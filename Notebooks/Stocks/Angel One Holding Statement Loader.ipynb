{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46095c9d-f686-4f48-8389-47c9e23f7214",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openpyxl\n",
    "%pip install msoffcrypto-tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f663794-de2d-4da8-aff0-ca643678a702",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "378736b3-8e07-4a97-a334-933db77c7404",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1759388724174}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List all files in the holdings directory and filter for Excel files\n",
    "files = [f for f in dbutils.fs.ls(\"/Volumes/personal_finance/default/files/angel_one/holdings\") if not f.isDir() and (f.name.endswith('.xlsx') or f.name.endswith('.xls'))]\n",
    "\n",
    "# Extract client id and formatted datetime from each file\n",
    "data = []\n",
    "for f in files:\n",
    "    match = re.search(r'Your_Holding_Details_([A-Z0-9]+)\\.xlsx', f.name)\n",
    "    client_id = match.group(1) if match else None\n",
    "    dt = datetime.fromtimestamp(f.modificationTime / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    path = f.path\n",
    "    if path.startswith(\"dbfs:\"):\n",
    "        path = path[5:]\n",
    "    data.append({\"name\": f.name, \"path\": path, \"modificationTime\": dt, \"client_id\": client_id, \"modTimeRaw\": f.modificationTime})\n",
    "\n",
    "file_info_df = pd.DataFrame(data)\n",
    "\n",
    "# Keep only the most recently modified file for each client_id\n",
    "file_info_df = file_info_df.sort_values(\"modTimeRaw\", ascending=False).drop_duplicates(subset=[\"client_id\"], keep=\"first\").drop(columns=[\"modTimeRaw\"])\n",
    "\n",
    "display(file_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc8b4df2-2dac-49f9-8a52-31c8a91de41d",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1759391155906}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import msoffcrypto\n",
    "import io\n",
    "# Create a new DataFrame for client_id to password mapping\n",
    "client_passwords_df = spark.sql(\"select * from personal_finance.bronze.angel_one_client_passwords\").toPandas()\n",
    "client_passwords = dict(zip(client_passwords_df['client_id'], client_passwords_df['password']))\n",
    "\n",
    "dfs = []\n",
    "for _, f in file_info_df.iterrows():\n",
    "    client_id = f.get(\"client_id\")\n",
    "    password = client_passwords.get(client_id)\n",
    "\n",
    "    with open(f[\"path\"], \"rb\") as file:\n",
    "        office_file = msoffcrypto.OfficeFile(file)\n",
    "        office_file.load_key(password=password)\n",
    "        decrypted = io.BytesIO()\n",
    "        office_file.decrypt(decrypted)\n",
    "        decrypted.seek(0)\n",
    "        df = pd.read_excel(\n",
    "            decrypted,\n",
    "            engine=\"openpyxl\", sheet_name=\"Equity\", skiprows=14\n",
    "        )\n",
    "        dfs.append(df)\n",
    "\n",
    "if dfs:\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "381559cd-de39-4f8f-a0c6-e2cb8c95a4c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for i, df in enumerate(dfs):\n",
    "    if \"Client ID\" in df.columns:\n",
    "        dfs[i] = df[df[\"Client ID\"] != \"Total\"]\n",
    "\n",
    "if dfs:\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6684c52d-e387-42a6-9631-c65a010c88a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(merged_df)\n",
    "spark_df = spark_df.toDF(*[c.replace(\" \", \"_\").replace(\"(\",\"\").replace(\")\",\"\") for c in spark_df.columns])\n",
    "spark_df.write.mode(\"overwrite\").saveAsTable(\"personal_finance.bronze.angel_one_holding_statement\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8916451455098158,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Angel One Holding Statement Loader",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
